<!DOCTYPE html>
<html lang="en-us">

<head>
</head>

<body>

  <section id="top" class="hero is-small">

    <div class="hero-head"></div>


    <div class="hero-body">

      <div class="container has-text-centered">

        <div class="subtitle is-3 ">

          <div style="font-size:x-large">

            <div class='col text-center' style="font-size:xx-large">
              <p>pTSE-T: Presentation Target Speaker Extraction using Unaligned Text Cues</p>
            </div>

            <div class='row text-center h5 font-weight-normal pl-0 pr-0 mb-4'>

              <a><span>Anonymous Author(s)</span></a>

            </div>

            <br>

          </div>

          <div class="">

            <div class="social-icons"> </div>

          </div>

        </div>

      </div>

      <div class="hero-foot ">

        <div class="container">
          <hr>
          <br>

          <nav class="navbar" role="navigation" aria-label="main navigation">

            <a role="button" class="navbar-burger" data-target="navMenu" aria-label="menu" aria-expanded="false">
              <span aria-hidden="true"></span>
              <span aria-hidden="true"></span>
              <span aria-hidden="true"></span>
            </a>
            <div class="navbar-menu has-content-centered" id="navMenu">


              <a class="navbar-item" href="#abstract">Abstract</a>

              <a class="navbar-item" href="#demos">Demos</a>
            </div>
          </nav>
          <br>

          <hr>
        </div>


      </div>
    </div>

  </section>

  <div class="section" id="abstract">

    <div class="container">
      <div class='col text-center'>
        <h2 class="title is-2 has-text-centered">Abstract</h2>
      </div>


      <div class="markdown has-text-centered">

        <div align="left" style="font-size:20px; text-align:justify">

          Target Speaker Extraction(TSE) aims to extract the clean speech of the target speaker in an audio mixture,
          thereby eliminating irrelevant background noise and speech. While prior works have explored various speaker
          cues including pre-recorded speech, visual information(e. g., lip motions and gestures), and spatial
          information, the acquisition and selection of such strong cues are intricate in many practical scenarios.
          Differently, in this paper, we condition the TSE algorithms on semantic cues based on limited and unaligned
          text content, such as some condensed points on a presentation slide, that could be useful in many scenarios
          such as in meetings, or poster and lecture presentations. We design two different networks. Specifically, our
          proposed Prompt Text Extractor Network(PTE) fuses audio features with content-based semantic cues to
          facilitate the generation of masks to filter out extraneous noise, while another proposal namely Text-Speech
          Recognition Network(TSR) employs contrastive learning techniques to associate blindly separated speech signals
          with semantic cues. The experimental results show the efficacy in accurately identifying the target speaker by
          utilizing semantic cues derived from limited and unaligned text, leading to the SI-SDRi of 12.16dB, SDRi
          of 12.66dB, PESQi of 0.830 and STOIi of 0.150.
          <br>
        </div>

      </div>

    </div>

    <div class="container has-text-centered top-pad">

      <a href="#top">

        <i class="fa fa-arrow-up"></i>

      </a>

    </div>

  </div>
  <div class="container">
    <hr>
  </div>

  <ul>

    <li><b>s1</b>: Sample one selected from MMSpeech dataset.</li>
    <li><b>s2</b>: Sample two selected from MMSpeech dataset.</li>
    <li><b>text1</b>: Prompt text corresponding to s1.</li>
    <li><b>text2</b>: Prompt text corresponding to s2.</li>
    <li><b>2mix</b>: Mixture of s1 and s2.</li>
    <li><b>
        <font color=#0000FF>PTE-s1</font>
      </b>: Given an input of mixture, processed through PTE network, with cue as prompt text one, the output sample.
    </li>

    <li><b>
        <font color=#0000FF>PTE-s2</font>
      </b>: Given an input of mixture, processed through PTE network, with cue as prompt text two, the output sample.
    </li>

    <li><b>AudioSep-s1</b>: Given an input of mixture, processed through finetuned AudioSep network, with cue as prompt
      text one,
      the output sample.</li>
    <li><b>AudioSep-s2</b>: Given an input of mixture, processed through finetuned AudioSep network, with cue as prompt
      text two,
      the output sample.</li>

    <li><b>CLAPSep-s1</b>: Given an input of mixture with postive prompt (here is prompt text one) and negative prompt
      (here is prompt text two), processed through finetuned CLAPSep network, with cue as prompt text one,
      the output sample.</li>
    <li><b>CLAPSep-s2</b>: Given an input of mixture with postive prompt (here is prompt text two) and negative prompt
      (here is prompt text one), processed through finetuned CLAPSep network, with cue as prompt text two,
      the output sample.</li>


  </ul>




  <div class="section" id="demos">

    <div class="container">

      <h2 class="title is-2 has-text-centered">Demos</h2>

      <div class="markdown has-text-centered">

        <!-- <h1 id="single-speaker-avd" class="anchor-link"><a href="#single-speaker-avd">Single-speaker AVD</a></h1> -->
        <table frame=void style="border:none; padding:0; margin:0">
          <colgroup>
            <col width="33%">
            <col width="33%">
            <col width="33%">
          </colgroup>

          <!-- CASE 1 -->

          <tbody>

            <tr style="button-margin:0">
              <td colspan="3" style="background-color:#FFFFFF; border:none; buttom-padding:0; margin:0">
                <b>
                  <font size="large" color="blue">2mix</font>
                </b>
              </td>
            </tr>


            <tr style="button-margin:0">
              <td colspan="3" style="background-color:#FFFFFF; border:none; buttom-padding:0; margin:0">
                <div>
                  <img src="slide1/1.png" style="width: 50%; display: block; height: auto;"></img>
                  <font size="large" color="black">text1: A person is discussing related work in separable convolution,
                    specifically a figure representing separable convolution with </font>
                  <font size="large" color="red">an input tensor of shape H x W x 3</font>,
                  and
                  mentioning depthwise convolution with a kernel size K x K x 3 x 3, followed by pointwise convolution
                  of size 1 x 1 with a kernel size K x K, outputting an output tensor with the same spatial dimensions
                  but possibly more channels. Other mentioned components include </font>
                  <font size="large" color="red">a standard convolution</font> figure and
                  parameters related to these convolutions. </font>
                </div>
              </td>
              <td colspan="3" style="background-color:#FFFFFF; border:none; buttom-padding:0; margin:0">
                <div>
                  <img src="slide2/1.png" style="width: 50%; display: block; height: auto;"></img>
                  <font size="large" color="black">text2: A person is discussing various methods for audio laughter
                    synthesis, including Method 1 using samples from the AmuS dataset, Method 2 based on the HTS method
                    from Speechlaughs, Method 3 utilizing a seq2seq model and trained data, and Method 4 enhancing
                    Method 3 with an additional waveform correction technique. </font>
                </div>
              </td>

            </tr>


            <tr style="button-margin:0">
              <td style="background-color:#FFFFFF; border:none; buttom-padding:0; margin:0">
                mixture
                <audio controls>
                  <source src="mixture/1.wav" type="audio/wav">
                </audio>
              </td>
              <td style="background-color:#FFFFFF; border:none; buttom-padding:0; margin:0">
                s1:
                <audio controls>
                  <source src="s1/1.wav" type="audio/wav">
                </audio>
              </td>
              <td style="background-color:#FFFFFF; border:none; buttom-padding:0; margin:0">
                s2:
                <audio controls>
                  <source src="s2/1.wav" type="audio/wav">
                </audio>
              </td>
              <td style="background-color:#FFFFFF; border:none; buttom-padding:0; margin:0">
                <font color=#0000FF>PTE-s1</font>
                <audio controls>
                  <source src="PTE-s1/1.wav" type="audio/wav">
                </audio>
              </td>
              <td style="background-color:#FFFFFF; border:none; buttom-padding:0; margin:0">
                <font color=#0000FF>PTE-s2</font>
                <audio controls>
                  <source src="PTE-s2/1.wav" type="audio/wav">
                </audio>
              </td>
              <td style="background-color:#FFFFFF; border:none; buttom-padding:0; margin:0">
                <font color=#0000FF>AudioSep-s1</font>
                <audio controls>
                  <source src="AudioSep-s1/1.wav" type="audio/wav">
                </audio>
              </td>
              <td style="background-color:#FFFFFF; border:none; buttom-padding:0; margin:0">
                <font color=#0000FF>AudioSep-s2</font>
                <audio controls>
                  <source src="AudioSep-s2/1.wav" type="audio/wav">
                </audio>
              </td>
              <td style="background-color:#FFFFFF; border:none; buttom-padding:0; margin:0">
                <font color=#0000FF>CLAPSep-s1</font>
                <audio controls>
                  <source src="CLAPSep-s1/1.wav" type="audio/wav">
                </audio>
              </td>
              <td style="background-color:#FFFFFF; border:none; buttom-padding:0; margin:0">
                <font color=#0000FF>CLAPSep-s2</font>
                <audio controls>
                  <source src="CLAPSep-s2/1.wav" type="audio/wav">
                </audio>
              </td>

              <!-- CASE 2 -->

            <tr style="button-margin:0">
              <td colspan="3" style="background-color:#FFFFFF; border:none; buttom-padding:0; margin:0">
                <div>
                  <img src="slide1/2.png" style="width: 50%; display: block; height: auto;"></img>
                  <font size="large" color="black">text1: A person is discussing <font size="large" color="red">
                      Text-to-Speech (TTS)</font> systems and their
                    speech encoders, emphasizing that these systems can learn <font size="large" color="red">speaker
                      information</font> without the need for
                    explicit <font size="large" color="red">speaker ID labels</font>. Speech input is being transformed
                    into text using an encoder, sometimes
                    employing Automatic Speech Recognition (ASR) representations without human annotation for text
                    input.
                </div>
              </td>
              <td colspan="3" style="background-color:#FFFFFF; border:none; buttom-padding:0; margin:0">
                <div>
                  <img src="slide2/2.png" style="width: 50%; display: block; height: auto;"></img>
                  <font size="large" color="black">text2: A person is discussing speech command recognition performance,
                    focusing on the Google Speech Commands dataset for v1 and v2, presenting various models, their
                    accuracy, and model parameters, mentioning <font size="large" color="red">MatchboxNet</font>,
                    ResNet15, DenseNetBC100, Attention RNN,
                    Harmonic Tensor 2DCNN, and Embedding Head Model, with reference to their respective papers and being
                    close to the state of the art with fewer parameters for both versions of the dataset. </font>
                </div>
              </td>

            </tr>





            <tr style="button-margin:0">
              <td style="background-color:#FFFFFF; border:none; buttom-padding:0; margin:0">
                mixture
                <audio controls>
                  <source src="mixture/2.wav" type="audio/wav">
                </audio>
              </td>
              <td style="background-color:#FFFFFF; border:none; buttom-padding:0; margin:0">
                s1:
                <audio controls>
                  <source src="s1/2.wav" type="audio/wav">
                </audio>
              </td>
              <td style="background-color:#FFFFFF; border:none; buttom-padding:0; margin:0">
                s2:
                <audio controls>
                  <source src="s2/2.wav" type="audio/wav">
                </audio>
              </td>
              <td style="background-color:#FFFFFF; border:none; buttom-padding:0; margin:0">
                <font color=#0000FF>PTE-s1</font>
                <audio controls>
                  <source src="PTE-s1/2.wav" type="audio/wav">
                </audio>
              </td>
              <td style="background-color:#FFFFFF; border:none; buttom-padding:0; margin:0">
                <font color=#0000FF>PTE-s2</font>
                <audio controls>
                  <source src="PTE-s2/2.wav" type="audio/wav">
                </audio>
              </td>
              <td style="background-color:#FFFFFF; border:none; buttom-padding:0; margin:0">
                <font color=#0000FF>AudioSep-s1</font>
                <audio controls>
                  <source src="AudioSep-s1/2.wav" type="audio/wav">
                </audio>
              </td>
              <td style="background-color:#FFFFFF; border:none; buttom-padding:0; margin:0">
                <font color=#0000FF>AudioSep-s2</font>
                <audio controls>
                  <source src="AudioSep-s2/2.wav" type="audio/wav">
                </audio>
              </td>
              <td style="background-color:#FFFFFF; border:none; buttom-padding:0; margin:0">
                <font color=#0000FF>CLAPSep-s1</font>
                <audio controls>
                  <source src="CLAPSep-s1/2.wav" type="audio/wav">
                </audio>
              </td>
              <td style="background-color:#FFFFFF; border:none; buttom-padding:0; margin:0">
                <font color=#0000FF>CLAPSep-s2</font>
                <audio controls>
                  <source src="CLAPSep-s2/2.wav" type="audio/wav">
                </audio>
              </td>

              <!-- CASE 3 -->



          </tbody>

        </table>

      </div>

    </div>

    <div class="container has-text-centered top-pad">

      <a href="#top">

        <i class="fa fa-arrow-up"></i>

      </a>

    </div>

  </div>

  <div class="container">
    <hr>
  </div>

  <h2 class="title is-2 has-text-centered">References</h2>
  <p><br>
  <ol>
    <li>Liu, Xubo, et al. "Separate anything you describe." arXiv preprint arXiv:2308.05037 (2023).
    </li>
    <li>Ma, Hao, et al. "CLAPSep: Leveraging Contrastive Pre-trained Models for Multi-Modal Query-Conditioned Target
      Sound Extraction." arXiv preprint arXiv:2402.17455 (2024).
    </li>
  </ol>
  </p>
  <br>


</body>

</html>